{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac724a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c508efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Spark session\n",
    "spark = SparkSession.builder.appName('SparNordBank').master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfe690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc =  spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87bd5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.94:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparNordBank</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23cbe79a490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8863c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries and types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType, LongType, BooleanType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b61612",
   "metadata": {},
   "source": [
    "### Reading the data from the files in HDFS by a specific schema using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e5ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom schema\n",
    "custom_schema = StructType([\n",
    "                        StructField('year', IntegerType(), nullable = True),\n",
    "                        StructField('month', StringType(), nullable = True),\n",
    "                        StructField('day', IntegerType(), nullable = True),\n",
    "                        StructField('weekday', StringType(), nullable = True),\n",
    "                        StructField('hour', IntegerType(), nullable = True),\n",
    "                        StructField('atm_status', StringType(), nullable = True),\n",
    "                        StructField('atm_id', StringType(), nullable = True),\n",
    "                        StructField('atm_manufacturer', StringType(), nullable = True),\n",
    "                        StructField('atm_location', StringType(), nullable = True),\n",
    "                        StructField('atm_streetname', StringType(), nullable = True),\n",
    "                        StructField('atm_street_number', IntegerType(), nullable = True),\n",
    "                        StructField('atm_zipcode', IntegerType(), nullable = True),\n",
    "                        StructField('atm_lat', DoubleType(), nullable = True),\n",
    "                        StructField('atm_lon', DoubleType(), nullable = True),\n",
    "                        StructField('currency', StringType(), nullable = True),\n",
    "                        StructField('card_type', StringType(), nullable = True),\n",
    "                        StructField('transaction_amount', IntegerType(), nullable = True),\n",
    "                        StructField('service', StringType(), nullable = True),\n",
    "                        StructField('message_code', StringType(), nullable = True),\n",
    "                        StructField('message_text', StringType(), nullable = True),\n",
    "                        StructField('weather_lat', DoubleType(), nullable = True),\n",
    "                        StructField('weather_lon', DoubleType(), nullable = True),\n",
    "                        StructField('weather_city_id', IntegerType(), nullable = True),\n",
    "                        StructField('weather_city_name', StringType(), nullable = True),\n",
    "                        StructField('temp', DoubleType(), nullable = True),\n",
    "                        StructField('pressure', IntegerType(), nullable = True),\n",
    "                        StructField('humidity', IntegerType(), nullable = True),\n",
    "                        StructField('wind_speed', IntegerType(), nullable = True),\n",
    "                        StructField('wind_deg', IntegerType(), nullable = True),\n",
    "                        StructField('rain_3h', DoubleType(), nullable = True),\n",
    "                        StructField('clouds_all', IntegerType(), nullable = True),\n",
    "                        StructField('weather_id', IntegerType(), nullable = True),\n",
    "                        StructField('weather_main', StringType(), nullable = True),\n",
    "                        StructField('weather_description', StringType(), nullable = True)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a55d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "etl_df = spark.read.csv('/user/root/ETL_Project_SPAR_NORD/part-m-00000' , header=False, schema = custom_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384a865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "etl_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716fa252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+-------+----+----------+------+----------------+------------+--------------+-----------------+-----------+-------+-------+--------+---------+------------------+------------+------------+------------+-----------+-----------+---------------+-----------------+----+--------+--------+----------+--------+-------+----------+----------+-------------------+-------------------+\n",
      "|year|month| day|weekday|hour|atm_status|atm_id|atm_manufacturer|atm_location|atm_streetname|atm_street_number|atm_zipcode|atm_lat|atm_lon|currency|card_type|transaction_amount|     service|message_code|message_text|weather_lat|weather_lon|weather_city_id|weather_city_name|temp|pressure|humidity|wind_speed|wind_deg|rain_3h|clouds_all|weather_id|       weather_main|weather_description|\n",
      "+----+-----+----+-------+----+----------+------+----------------+------------+--------------+-----------------+-----------+-------+-------+--------+---------+------------------+------------+------------+------------+-----------+-----------+---------------+-----------------+----+--------+--------+----------+--------+-------+----------+----------+-------------------+-------------------+\n",
      "|null|month|null|weekday|null|atm_status|atm_id|atm_manufacturer|atm_location|atm_streetname|             null|       null|   null|   null|currency|card_type|              null|message_code|message_text| weather_lat|       null|       null|           null|             temp|null|    null|    null|      null|    null|   null|      null|      null|weather_description|               null|\n",
      "+----+-----+----+-------+----+----------+------+----------------+------------+--------------+-----------------+-----------+-------+-------+--------+---------+------------------+------------+------------+------------+-----------+-----------+---------------+-----------------+----+--------+--------+----------+--------+-------+----------+----------+-------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the imported dataset\n",
    "etl_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b15b713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the schema\n",
    "etl_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9bd6b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekday',\n",
       " 'hour',\n",
       " 'atm_status',\n",
       " 'atm_id',\n",
       " 'atm_manufacturer',\n",
       " 'atm_location',\n",
       " 'atm_streetname',\n",
       " 'atm_street_number',\n",
       " 'atm_zipcode',\n",
       " 'atm_lat',\n",
       " 'atm_lon',\n",
       " 'currency',\n",
       " 'card_type',\n",
       " 'transaction_amount',\n",
       " 'service',\n",
       " 'message_code',\n",
       " 'message_text',\n",
       " 'weather_lat',\n",
       " 'weather_lon',\n",
       " 'weather_city_id',\n",
       " 'weather_city_name',\n",
       " 'temp',\n",
       " 'pressure',\n",
       " 'humidity',\n",
       " 'wind_speed',\n",
       " 'wind_deg',\n",
       " 'rain_3h',\n",
       " 'clouds_all',\n",
       " 'weather_id',\n",
       " 'weather_main',\n",
       " 'weather_description']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns\n",
    "etl_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f70cd",
   "metadata": {},
   "source": [
    "### Creation of 4 Dimensions & 1 Fact tables using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606be20d",
   "metadata": {},
   "source": [
    "•\tATM dimension - This dimension will have the data related to the various ATMs present in the dataset along with the ATM number(ATM ID in the original dataset), ATM manufacturer and a reference to the ATM location and is very important for solving analytical queries related where ATM data will be used.\n",
    "\n",
    "•\tLocation dimension - This is a very important dimension containing all the location data including location name, street name, street number, zip code and even the latitude and longitude. This information will be very important for solving problems related to the particular location at which a transaction took place and can help banks in things like pinpointing locations where ATMs where demand is higher as compared to other locations. Combined with weather data in the transaction table, this can be used to further do analysis such as how weather affects the demand at ATMs at a particular location.\n",
    "\n",
    "•\tDate dimension - This is another very important dimension which is almost always present where data such as transactional data is being dealt with. This dimension includes fields such as the full date and time timestamp, year, month, day, hour as well as the weekday for a transaction. This all can help in analysing the transaction behaviour with respect to the time at which the transaction took place and also how the transaction activity varies between weekdays and weekends.\n",
    "\n",
    "•\tCard type dimension - This dimension has the information about the particular card type with which a particular transaction took place. This can help in performing analysis on how the number of transactions varies with respect to each different card type.\n",
    "\n",
    "•\tTransaction fact - This is the actual fact table for the data set which contains all of the numerical data such as the currency of the transaction, service, transaction amount, message code and text as well as weather info such as description, weather id etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed93b9",
   "metadata": {},
   "source": [
    "### *********************************************Location dimension*************************************************\n",
    "location_id INT\n",
    "location VARCHAR(50)\n",
    "streetname VARCHAR(255)\n",
    "street_number INT\n",
    "zipcode INT\n",
    "lat DECIMAL(10,3)\n",
    "lon DECIMAL(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbefb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de53e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Location dimension\n",
    "df_location = etl_df.select('atm_location', 'atm_streetname', 'atm_street_number', 'atm_zipcode', 'atm_lat', 'atm_lon')\\\n",
    "            .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da6258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_location.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f3a096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+-----------+-----------+-----------+\n",
      "|atm_location|      atm_streetname|atm_street_number|atm_zipcode|    atm_lat|    atm_lon|\n",
      "+------------+--------------------+-----------------+-----------+-----------+-----------+\n",
      "|  Middelfart|             Brogade|                9|       5500|55.50686976| 9.72743835|\n",
      "|     Randers|           Østervold|               16|       8900|56.46187753|10.03778506|\n",
      "|    Sæby Syd|Trafikcenter Sæby...|                1|       9300|  57.313053| 10.4496415|\n",
      "+------------+--------------------+-----------------+-----------+-----------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_location.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087ff87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the primary key location_id & renaming columns below as per requirement\n",
    "df_location = df_location.select(row_number().over(Window.orderBy(df_location['atm_location'])).alias('location_id'),'*')\\\n",
    "                            .withColumnRenamed('atm_location','location')\\\n",
    "                            .withColumnRenamed('atm_streetname','streetname')\\\n",
    "                            .withColumnRenamed('atm_street_number','street_number')\\\n",
    "                            .withColumnRenamed('atm_zipcode','zipcode')\n",
    "                            #.withColumnRenamed('atm_lat','lat')\\\n",
    "                            #.withColumnRenamed('atm_lon','lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5062ed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+-------------+-------+-----------+-----------+\n",
      "|location_id|            location|  streetname|street_number|zipcode|    atm_lat|    atm_lon|\n",
      "+-----------+--------------------+------------+-------------+-------+-----------+-----------+\n",
      "|          1|             Aabybro|   Østergade|            6|   9440|57.16215457| 9.73008178|\n",
      "|          2|      Aalborg Hallen|Europa Plads|            4|   9000|57.04365629| 9.91267605|\n",
      "|          3|Aalborg Storcente...|    Hobrovej|          452|   9200|57.00479614| 9.87593478|\n",
      "|          4|Aalborg Storcente...|    Hobrovej|          452|   9200|57.00479614| 9.87593478|\n",
      "|          5|              Aalbæk|  Centralvej|            5|   9982|57.59326139|10.41166458|\n",
      "+-----------+--------------------+------------+-------------+-------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating changes in the dimension records\n",
    "df_location.orderBy(df_location['location']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b6660c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_location.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4a6d2",
   "metadata": {},
   "source": [
    "### ***********************************************ATM dimension*************************************************************\n",
    "atm_id INT\n",
    "atm_number VARCHAR(20)\n",
    "atm_manufacturer VARCHAR(50)\n",
    "atm_location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6d70f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ATM dimension & renaming the columns as below\n",
    "df_atm = etl_df.select('atm_id', 'atm_manufacturer', 'atm_lat', 'atm_lon','atm_location')\\\n",
    "        .withColumnRenamed('atm_id','atm_number').distinct()\\\n",
    "        .withColumnRenamed('atm_location','location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95eaf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-----------+-----------+-----------+\n",
      "|atm_number|atm_manufacturer|    atm_lat|    atm_lon|   location|\n",
      "+----------+----------------+-----------+-----------+-----------+\n",
      "|        25| Diebold Nixdorf|55.39420346|10.36993204|     Odense|\n",
      "|        91|             NCR|56.56678482| 9.02660419|Skive Lobby|\n",
      "+----------+----------------+-----------+-----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating changes in the dimension records\n",
    "df_atm.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cad7f1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_atm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a7d7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining with location dimension to fetch location_id column\n",
    "df_atm_dim = df_atm.join(df_location, on=['location', 'atm_lat','atm_lon'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efee055d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_atm_dim.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e71baec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+----------+----------------+-----------+-------------+-------------+-------+\n",
      "|   location|    atm_lat|    atm_lon|atm_number|atm_manufacturer|location_id|   streetname|street_number|zipcode|\n",
      "+-----------+-----------+-----------+----------+----------------+-----------+-------------+-------------+-------+\n",
      "|Nørresundby| 57.0586772|  9.9224726|       105| Diebold Nixdorf|         73|       Torvet|            6|   9400|\n",
      "|   Hillerød|55.93325641|12.31363816|        57|             NCR|         33|Københavnsvej|           31|   3400|\n",
      "|     Odense|55.39420346|10.36993204|        25| Diebold Nixdorf|         74|    Fælledvej|            3|   5000|\n",
      "+-----------+-----------+-----------+----------+----------------+-----------+-------------+-------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating changes in the dimension records\n",
    "df_atm_dim.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3089400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the primary key atm_id & renaming columns below as per requirement\n",
    "DIM_ATM = df_atm_dim.select(row_number().over(Window.orderBy('atm_number')).alias('atm_id'),\\\n",
    "            'atm_number', 'atm_manufacturer','location_id')\\\n",
    "            .withColumnRenamed('location_id','atm_location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83de95e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "DIM_ATM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d6a9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns as below in location dimension\n",
    "DIM_LOCATION = df_location.withColumnRenamed('atm_lat','lat')\\\n",
    "                             .withColumnRenamed('atm_lon','lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c033fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "DIM_LOCATION.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5508a7",
   "metadata": {},
   "source": [
    "### ***********************************************Date dimension **********************************************************\n",
    "date_id INT\n",
    "full_date_time TIMESTAMP\n",
    "year INT\n",
    "month VARCHAR(20)\n",
    "day INT\n",
    "hour INT\n",
    "weekday VARCHAR(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e54db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the date dimension\n",
    "df_date = etl_df.select('year', 'month', 'day', 'hour', 'weekday').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd841db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4348"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_date.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53e332ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+----+-------+\n",
      "|year|  month|day|hour|weekday|\n",
      "+----+-------+---+----+-------+\n",
      "|2017|January|  1|   9| Sunday|\n",
      "|2017|January|  3|   5|Tuesday|\n",
      "|2017|January|  8|  19| Sunday|\n",
      "+----+-------+---+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating the records\n",
    "df_date.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21acf89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+----+-------+-------------------+\n",
      "|year|month  |day|hour|weekday|full_date_time     |\n",
      "+----+-------+---+----+-------+-------------------+\n",
      "|2017|January|1  |9   |Sunday |2017-01-01 09:00:00|\n",
      "|2017|January|3  |5   |Tuesday|2017-01-03 05:00:00|\n",
      "|2017|January|8  |19  |Sunday |2017-01-08 19:00:00|\n",
      "+----+-------+---+----+-------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the logic for full_date_time column as timestamp\n",
    "df_date\\\n",
    ".withColumn('full_date_time',from_unixtime(unix_timestamp(concat_ws(' ', 'year', 'month', 'day', 'hour'),'yyyy MMMM d H')))\\\n",
    ".show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56735657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including the full_date_time column in date dimension\n",
    "df_date = df_date\\\n",
    ".withColumn('full_date_time',from_unixtime(unix_timestamp(concat_ws(' ', 'year', 'month', 'day', 'hour'),'yyyy MMMM d H')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67d84174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4348"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_date.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c860edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the primary key location_id & selecting columns below as per requirement\n",
    "DIM_DATE = df_date.select(row_number().over(Window.orderBy('full_date_time')).alias('date_id'),\\\n",
    "              'full_date_time', 'year', 'month', 'day', 'hour', 'weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83df3925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4348"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "DIM_DATE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b9eca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+-------+----+----+-------+\n",
      "|date_id|     full_date_time|year|  month| day|hour|weekday|\n",
      "+-------+-------------------+----+-------+----+----+-------+\n",
      "|      1|               null|null|  month|null|null|weekday|\n",
      "|      2|2017-01-01 00:00:00|2017|January|   1|   0| Sunday|\n",
      "|      3|2017-01-01 01:00:00|2017|January|   1|   1| Sunday|\n",
      "|      4|2017-01-01 02:00:00|2017|January|   1|   2| Sunday|\n",
      "+-------+-------------------+----+-------+----+----+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating the records\n",
    "DIM_DATE.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92b579",
   "metadata": {},
   "source": [
    "### ***********************************************Card type dimension*******************************************************\n",
    "card_type_id INT\n",
    "card_type VARCHAR(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94fd5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the cardtype dimension\n",
    "df_card = etl_df.select('card_type').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4d9d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "df_card.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a8f0a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      card_type|\n",
      "+---------------+\n",
      "|Dankort - on-us|\n",
      "|         CIRRUS|\n",
      "+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating the records\n",
    "df_card.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88367b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the primary key card_type_id\n",
    "DIM_CARD_TYPE = df_card.select(row_number().over(Window.orderBy('card_type')).alias('card_type_id'),'card_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "164ac7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "DIM_CARD_TYPE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88b58d",
   "metadata": {},
   "source": [
    "### ***********************************************Transaction fact*******************************************************\n",
    "trans_id BIGINT\n",
    "atm_id INT\n",
    "weather_loc_id INT\n",
    "date_id INT\n",
    "card_type_id INT\n",
    "atm_status VARCHAR(20)\n",
    "currency VARCHAR(10)\n",
    "service VARCHAR(20)\n",
    "transaction_amount INT\n",
    "message_code VARCHAR(255)\n",
    "message_text VARCHAR(255)\n",
    "rain_3h DECIMAL(10,3)\n",
    "clouds_all INT\n",
    "weather_id INT\n",
    "weather_main VARCHAR(50)\n",
    "weather_description VARCHAR(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5059a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Transaction fact \n",
    "FACT_ATM_TRANS = etl_df\\\n",
    "# Rename below columns as per requirement\n",
    "    .withColumnRenamed('atm_location','location')\\\n",
    "    .withColumnRenamed('atm_streetname','streetname')\\\n",
    "    .withColumnRenamed('atm_street_number','street_number')\\\n",
    "    .withColumnRenamed('atm_zipcode','zipcode')\\\n",
    "    .withColumnRenamed('atm_lat','lat')\\\n",
    "    .withColumnRenamed('atm_lon','lon')\\\n",
    "# Join with DIM_LOCATION\n",
    "    .join(DIM_LOCATION, on=['location', 'streetname', 'street_number', 'zipcode', 'lat', 'lon'], how = 'left')\\\n",
    "# Rename 'atm_id'-> 'atm_number'   &   'location_id' -> 'atm_location_id'\n",
    "    .withColumnRenamed('atm_id', 'atm_number')\\\n",
    "    .withColumnRenamed('location_id', 'atm_location_id')\\\n",
    "# Join with DIM_ATM\n",
    "    .join(DIM_ATM, on = ['atm_number', 'atm_manufacturer', 'atm_location_id'], how = 'left')\\\n",
    "# Join with DIM_DATE\n",
    "    .join(DIM_DATE, on = ['year', 'month', 'day', 'hour', 'weekday'], how = 'left')\\\n",
    "# Join with DIM_CARD_TYPE\n",
    "    .join(DIM_CARD_TYPE, on = ['card_type'], how = 'left')\\\n",
    "# Rename atm_location_id to weather_loc_id\n",
    "    .withColumnRenamed('atm_location_id', 'weather_loc_id')\\\n",
    "# Create trans_id \n",
    "    .withColumn(\"trans_id\", row_number().over(Window.orderBy('date_id')))\\\n",
    "# Select only required columns in final fact \n",
    "    .select('trans_id', 'atm_id', 'weather_loc_id', 'date_id', 'card_type_id','atm_status', 'currency',\\\n",
    "            'service', 'transaction_amount', 'message_code', 'message_text', 'rain_3h',\\\n",
    "            'clouds_all', 'weather_id', 'weather_main', 'weather_description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db17cf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250001"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the record count\n",
    "FACT_ATM_TRANS.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73f86bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the original record count\n",
    "etl_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e0a5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+-------+------------+----------+--------+------------+------------------+------------+------------+-------+----------+----------+-------------------+-------------------+\n",
      "|trans_id|atm_id|weather_loc_id|date_id|card_type_id|atm_status|currency|     service|transaction_amount|message_code|message_text|rain_3h|clouds_all|weather_id|       weather_main|weather_description|\n",
      "+--------+------+--------------+-------+------------+----------+--------+------------+------------------+------------+------------+-------+----------+----------+-------------------+-------------------+\n",
      "|       1|  null|          null|   null|          13|atm_status|currency|message_code|              null|message_text| weather_lat|   null|      null|      null|weather_description|               null|\n",
      "|       2|    26|            38|      2|           8|    Active|     DKK|        null|              null|        null|   56.643059|   92.0|       500|      null|         light rain|               null|\n",
      "+--------+------+--------------+-------+------------+----------+--------+------------+------------------+------------+------------+-------+----------+----------+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validationg the records\n",
    "FACT_ATM_TRANS.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0889cd2",
   "metadata": {},
   "source": [
    "### Loading the dimension and fact tables into Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LOCATION.coalesce(1).write.format('csv').option('header','false').save('s3://etl-project/dim_location', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing data from pyspark df 'dim_atm' in csv format to dim_atm folder in S3 bucket 'upgrad-bucket-s3'\n",
    "DIM_ATM.coalesce(1).write.format('csv').option('header','false').save('s3://etl-project/dim_atm', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing data from pyspark df 'dim_data' in csv format to dim_data folder in S3 bucket 'upgrad-bucket-s3'\n",
    "DIM_DATE.coalesce(1).write.format('csv').option('header','false').save('s3://etl-project/dim_date', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing data from pyspark df 'dim_card_type' in csv format to dim_card_type folder in S3 bucket 'upgrad-bucket-s3'\n",
    "DIM_CARD_TYPE.coalesce(1).write.format('csv').option('header','false').save('s3://etl-project/dim_card_type', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdee43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing data from pyspark df 'fact_atm_trans' in csv format to fact_atm_trans folder in S3 bucket 'upgrad-bucket-s3'\n",
    "FACT_ATM_TRANS.coalesce(1).write.format('csv').option('header','false').save('s3://etl-project/fact_atm_trans', mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
